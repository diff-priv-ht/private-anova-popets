\documentclass{beamer}
\usetheme{Boadilla}
\usepackage{ulem}
\usepackage{xspace}
\usepackage{xcolor}
\usepackage{centernot}


\newcommand{\sse}{\textit{SSE}\xspace}
\newcommand{\ssa}{\textit{SSA}\xspace}
\newcommand{\se}{\textit{SE}\xspace}
\newcommand{\sa}{\textit{SA}\xspace}
\newcommand{\lap}{\ensuremath{{\sf Lap}}\xspace}


\beamertemplatenavigationsymbolsempty

\title[Improved Private ANOVA]{Improved Differentially Private Analysis of Variance}
\author[Marika Swanberg]{\textcolor{red}{Marika Swanberg} \and Ira Globus-Harris \and Iris Griffith \and \newline Anna Ritz \and  Andrew Bray \and Adam Groce}
\date{Reed College}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

%\begin{frame}{Outline}
%  \tableofcontents
%  % You might wish to add the option [pausesections]
%\end{frame}

% Section and subsections will appear in the presentation overview
% and table of contents.
\section{Differential Privacy}

\begin{frame}{Observed Data, $n=30$}
\begin{figure}
  \includegraphics[scale=0.5]{simulation/observed-plot}
\end{figure}
\pause
Are gene allele and tumor size dependent?
\end{frame}

\begin{frame}{Metric for dependency}

\begin{equation*}
F\text{-test} = \frac{\text{Variation between groups}}{\text{In-group variation}} \pause 
\end{equation*}

\begin{equation*}
\ssa(D) = \sum_{j=1}^{k} n_j (\bar{y}_j - \bar{y})^2/(k-1)
\end{equation*}

\begin{equation*}
\sse(D) = \sum_{i=1}^{n}  (y_{i}-\bar{y}_{c_i})^2/(n-k)
\end{equation*}
\end{frame}


\begin{frame}{Simulate Random Data}
\begin{figure}
  \includegraphics[scale=0.60]{simulation/null-plots}
\end{figure}
\end{frame}

\begin{frame}{}
\begin{figure}
  \includegraphics[scale=0.85]{simulation/null-dist}
\end{figure} 
Now do we think our data supports independence of gene allele and tumor size?
\end{frame}

\begin{frame}{Why is $F$-test optimal?}
\pause
High probability of indicating dependence when variables \emph{are} dependent \ldots\pause  

\bigskip
\ldots even when dataset is small.

\pause
\begin{definition}[Power]
The \textbf{power} of a hypothesis test is the probability it rejects $H_0$.  It depends on the alternate distribution $H_A$ and $n$.
\end{definition}
\bigskip 

\pause
Goal of any test statistic is achieving high power$^*$.
\end{frame}

\begin{frame}{Observed Data, $n=30$}
\begin{figure}
  \includegraphics[scale=0.5]{simulation/observed-plot}
\end{figure}
What if we want to keep this data private?
\end{frame}

% SLIDE 3
\begin{frame}{Differential privacy [DMNS06]}

\begin{definition}
Two databases are \textbf{neighboring} if they differ only in the data of one individual.
\end{definition}
\pause
\begin{definition}
A query $f$ is \textbf{$\varepsilon$-differentially private} if for all neighboring databases $D, D'$ and all output sets $S$
\begin{equation*}
\Pr[f(D) \in S] \leq e^\varepsilon \Pr[f(D') \in S].
\end{equation*}
\end{definition}
\end{frame}

% SLIDE 4
\begin{frame}{Properties of differential privacy [DMNS06]}
\begin{theorem}[Post-processing]
If $f$ is $\varepsilon$-differentially private then for any (randomized) function $g$, then if $h(D) = g(f(D)$, $h$ is also $\varepsilon$-differentially private.
\end{theorem}
\pause
\begin{theorem}[Composition]
If $f$ is $\varepsilon_1$-differentially private and $g$ is $\varepsilon_2$-differentially private then if $h(D) = (g(D), f(D))$, $h$ is  $(\varepsilon_1+\varepsilon_2)$-differentially private.
\end{theorem}
\end{frame}

% SLIDE 5
\begin{frame}{Laplace mechanism}
\begin{definition}[Sensitivity]
The sensitivity $\Delta f$ of a deterministic, real-valued function $f$ on databases is the maximum over all pairs of neighboring $D, D'$ of $| f(D) - f(D') |$.
\end{definition}

\pause
\begin{theorem}[Laplace Mechanism]
Given any deterministic, real-valued function $f$ on databases, define $\widehat{f}$ as
$$\widehat{f}(D) = f(D) + Y,$$
where $Y \leftarrow \lap(\Delta f/\varepsilon)$. The Laplace mechanism is $\varepsilon$-differentially private.
\end{theorem}
\end{frame}

% SLIDE 5
\begin{frame}{Related Works}
    Other work on private hypothesis testing:\pause
\begin{itemize}
\item Asymptotic analysis [WZ10, Smith11, CKMSU19] \pause
\item Chi-squared test (difference of discrete distributions) [VS09, FSU11, JS13, USF13, WLK15, GLRV16, RK17] \pause
\item Other tests: \pause
\begin{itemize}
\item Binomial data [AS18] (Proven optimal!) \pause
\item Difference of two means [OHK15, DNLI18] \pause
\item Linear regression [BRMC17, Sheffet17] \pause
\end{itemize}
\end{itemize}
Earlier work is often missing: \pause
\begin{itemize}
\item Rigorous p-value computations \pause
\item Power analysis
\end{itemize}
\end{frame}

\begin{frame}{Private $F$-statistic [CBRG18]}
Assume data is on the $[0,1]$ interval. \pause
\begin{theorem}
\sse has sensitivity bounded by 7.
\end{theorem}
\pause
$$\widehat{\sse}(D) = \sse(D) + \lap(7/\varepsilon) $$
\pause
\begin{theorem}
\ssa has sensitivity bounded by $9 + 5/n$.
\end{theorem}
\pause
$$\widehat{\ssa}(D) = \ssa(D) + \lap\left(\frac{9+5/n}{\varepsilon}\right) $$
\end{frame}

% SLIDE 9
\begin{frame}{Private ANOVA [CBRG18]}
$$\widehat{F}(D) = \frac{\widehat{\ssa}(D)/(k-1)}{\widehat{\sse}(D)/(n-k)}$$
\bigskip

 \pause
 \centering
Problem: What is the reference distribution now?
\end{frame}


\begin{frame}{Private ANOVA [CBRG18]}
\begin{figure}
  \includegraphics[scale=0.3]{images/noisy-ref-dist}
\end{figure} 
\centering
Public reference distribution gives inaccurate $p$-values.
\end{frame}


\begin{frame}{Private ANOVA [CBRG18]}
  \begin{figure}
  \includegraphics[scale=0.45]{images/campbellpower}
  \end{figure}
  \begin{definition}[Power]
The \textbf{power} of a hypothesis test is the probability it rejects $H_0$.  It depends on the alternate distribution $H_A$ and $n$.
\end{definition}
\end{frame}


\begin{frame}{Improving ANOVA [\textcolor{red}{S}HGRGB19]}
Are there other ways of measuring ``dispersion'' (analogous to variance)? \pause
$$(x_i - \bar{x})^2, \quad \lvert x_i - \bar{x} \rvert, \text{ or maybe }\lvert x_i - \bar{x} \rvert^?$$  \pause
\begin{align*}
\ssa(D) = \sum_{j=1}^{k} n_j (\bar{y}_j - \bar{y})^2  &\Longrightarrow \textcolor{blue}{ \sa(D) = \sum_{j=1}^{k} n_j |\bar{y}_j - \bar{y}| }\\  
\sse(D) = \sum_{i=1}^{n}  (y_{i}-\bar{y}_{c_i})^2  &\Longrightarrow \textcolor{blue}{\se(D) = \sum_{i=1}^{n}  |y_{i}-\bar{y}_{c_i}| } \\  
F(D) = \frac{\ssa(D)/(k-1)}{\sse(D)/(n-k)} &\Longrightarrow  \textcolor{blue} {F_1(D) = \frac{\sa(D)/(k-1)}{\se(D)/(n-k)}}
\end{align*}
 \pause
The new $F_1$ statistic has: \pause
\begin{itemize}
\item Lower sensitivity (3 for \se, 4 for \sa) \pause
\item Much higher typical value 
\end{itemize}
\end{frame}



\begin{frame}{Improving ANOVA [\textcolor{red}{S}HGRGB19]}
Computing $F_1$ privately \pause
\begin{enumerate}
	\item $\widehat{\sa}  = \sa + \lap(4/\rho\varepsilon)$
    \item $\widehat{\se} = \sa + \lap(3/(1-\rho)\varepsilon)$ \pause
    \item $\widehat{F}_1 = \frac{\widehat{\sa}/(k-1)}{\widehat{\se}/(n-k)}$ \pause
\end{enumerate}
Where $\rho$ denotes epsilon allocation
\begin{itemize}
	\item Empirically checked: optimal $\rho \approx 0.7$ \pause
\end{itemize}
Computing accurate $p$-values \pause
\begin{itemize}
	\item Simulate reference distribution of $\widehat{F}_1$ \pause
	\item Problem: reference distribution depends on $\sigma$
\end{itemize}
\end{frame}


\begin{frame}{Improving ANOVA [\textcolor{red}{S}HGRGB19]}
Need private estimate of $\sigma$ \pause
\begin{itemize}
	\item Allocate some of epsilon budget? \pause
	\item Solution: derive an unbiased estimator for $\sigma$ \pause
\end{itemize}
\bigskip

$$\hat{\sigma} = \sqrt{\pi/2} \cdot \frac{\widehat{SE}}{(N-k)} $$ \pause
\bigskip
Proceed with simulation
\bigskip

Empirically verified to have valid $p$-values.
\end{frame}


\begin{frame}{}
  \begin{figure}
  \includegraphics[scale=0.12]{images/f1-vs-f2}
  \end{figure}

\end{frame}

\begin{frame}{Further Optimization}
Are there other ways of measuring ``dispersion'' (analogous to variance)? 
$$(x_i - \bar{x})^2, \quad \lvert x_i - \bar{x} \rvert, \text{ or maybe }\lvert x_i - \bar{x} \rvert^?$$  \pause

Perhaps a different exponent? \pause Turns out 1 is optimal.
\end{frame}

\begin{frame}{Conclusion}
\large In the private framework \ldots \par
 \normalsize
\begin{itemize}
	\item Not limited to closed-form test statistics
	\item Room for massive power gains 
	\item Optimal public test $\centernot \implies$ optimal private test
\end{itemize}

\large \ldots all of statistics is fair game.
 \normalsize
 
 \begin{block}{New developments}
[CKSBG19] gained another order of magnitude improvement. See \textit{Differentially Private Nonparametric Hypothesis Testing} at CCS `19.
 \end{block}

This material is based upon work supported by the National Science Foundation under Grant No. SaTC-1817245 and by the Gillespie Family Student Research Fund.
\end{frame}



\begin{frame}{}
    \begin{center}
        \Huge Thank you
    \end{center}    
\end{frame}



\end{document}
